{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs, gc\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert后面接textcnn需要NonMasking\n",
    "class NonMasking(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(NonMasking, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        input_shape = input_shape\n",
    " \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    " \n",
    "    def call(self, x, mask=None):\n",
    "        return x\n",
    " \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config_path, checkpoint_path):\n",
    "    bert_model = load_trained_model_from_checkpoint(\n",
    "        config_path, checkpoint_path)\n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = False\n",
    "    T1 = Input(shape=(512,))\n",
    "    T2 = Input(shape=(512,))\n",
    "    T = bert_model([T1, T2])\n",
    "    T = NonMasking()(T)\n",
    "    convs = []\n",
    "    for kernel_size in [3, 4, 5]:\n",
    "        c = Conv1D(32, kernel_size, activation='relu',padding='same')(T)\n",
    "        c = GlobalMaxPooling1D()(c)\n",
    "        convs.append(c)\n",
    "    x = Concatenate()(convs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(119, activation='softmax')(x)\n",
    "    model = Model([T1, T2], output)\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(1e-5),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 512, 768)     101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "non_masking (NonMasking)        (None, 512, 768)     0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 32)      73760       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 512, 32)      98336       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 32)      122912      non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 119)          11543       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 101,983,607\n",
      "Trainable params: 306,551\n",
      "Non-trainable params: 101,677,056\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 512, 768)     101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "non_masking (NonMasking)        (None, 512, 768)     0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 32)      73760       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 512, 32)      98336       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 32)      122912      non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 119)          11543       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 101,983,607\n",
      "Trainable params: 306,551\n",
      "Non-trainable params: 101,677,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config_path =r'E:\\chinese_L-12_H-768_A-12\\new\\bert_config.json'\n",
    "checkpoint_path = r'E:\\chinese_L-12_H-768_A-12\\new\\bert_model.ckpt'\n",
    "dict_path =  r'E:\\chinese_L-12_H-768_A-12\\new\\vocab.txt'\n",
    "\n",
    "model_clf = get_model(config_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('train.csv',encoding='utf-8')\n",
    "data_dev=pd.read_csv('dev.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_inde(text):\n",
    "    tokenizer = Tokenizer(token_dict)\n",
    "    indices, segments = tokenizer.encode(text, max_len=512)\n",
    "    return indices\n",
    " \n",
    "def token_segm(text):\n",
    "    tokenizer = Tokenizer(token_dict)\n",
    "    indices, segments = tokenizer.encode(text, max_len=512)\n",
    "    return segments\n",
    " \n",
    "# tokenizer = Tokenizer(token_dict)\n",
    "# 进行bert token处理\n",
    "# df['cutted'] = df['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "#训练集处理\n",
    "data_train['indices']=data_train['sentence'].apply(token_inde)\n",
    "data_train['segments']=data_train['sentence'].apply(token_segm)\n",
    "#测试集处理\n",
    "data_dev['indices']=data_dev['sentence'].apply(token_inde)\n",
    "data_dev['segments']=data_dev['sentence'].apply(token_segm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y值处理成功类别共计*** 119\n"
     ]
    }
   ],
   "source": [
    "#label类别处理(y值即label的映射，label的数量) eg：'体育':1  1:'新闻'\n",
    "label = list(set(data_train['label_des'].tolist()))\n",
    "dig_lables = dict(enumerate(label))\n",
    "lable_dig = dict((lable, dig) for dig, lable in dig_lables.items())\n",
    "print('y值处理成功类别共计***', len(lable_dig))\n",
    "data_train['label_new'] = data_train['label_des'].apply(lambda lable: lable_dig[lable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别保存到本地\n",
    "import json\n",
    "item = json.dumps(dig_lables, ensure_ascii=False, indent=4)\n",
    "with open('label.json','w',encoding='utf-8') as f:\n",
    "    f.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集x和y\n",
    "train_data = [np.array(data_train['indices'].tolist()),np.array(data_train['segments'].tolist())]\n",
    "train_lables = to_categorical(data_train['label'],num_classes=len(label))\n",
    " \n",
    "#测试集\n",
    "test_data= [np.array(data_dev['indices'].tolist()),np.array(data_dev['segments'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 512, 768)     101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "non_masking (NonMasking)        (None, 512, 768)     0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 32)      73760       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 512, 32)      98336       non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 32)      122912      non_masking[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 119)          11543       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 101,983,607\n",
      "Trainable params: 306,551\n",
      "Non-trainable params: 101,677,056\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "model_clf.summary()\n",
    "model_clf.fit(train_data,train_lables,epochs=2, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "from sklearn import metrics\n",
    "test_predict=model_clf.predict(test_data)\n",
    "test['bert_textcnn预测']=[dig_lables[test_predict[i].argmax()] for i in range(len(test_predict))]\n",
    " \n",
    "print('result:',metrics.accuracy_score(test['text'],test['bert_textcnn预测']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
